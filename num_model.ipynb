{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from utils import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data_balance.csv', encoding='utf8')\n",
    "test = pd.read_csv('test.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1566, 4) (1566,)\n",
      "(1020, 4) (1020,)\n",
      "KNN model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.006s\n",
      "Time to predict train set: 0.036s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76       653\n",
      "           1       0.75      0.69      0.72       599\n",
      "\n",
      "    accuracy                           0.74      1252\n",
      "   macro avg       0.74      0.74      0.74      1252\n",
      "weighted avg       0.74      0.74      0.74      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.045s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.66       167\n",
      "           1       0.60      0.52      0.56       147\n",
      "\n",
      "    accuracy                           0.61       314\n",
      "   macro avg       0.61      0.61      0.61       314\n",
      "weighted avg       0.61      0.61      0.61       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.025s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.78       833\n",
      "           1       0.30      0.58      0.39       187\n",
      "\n",
      "    accuracy                           0.67      1020\n",
      "   macro avg       0.59      0.64      0.59      1020\n",
      "weighted avg       0.77      0.67      0.71      1020\n",
      "\n",
      "****************************************************************************************************\n",
      "Gaussian model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.001s\n",
      "Time to predict train set: 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.06      0.11       653\n",
      "           1       0.49      0.99      0.66       599\n",
      "\n",
      "    accuracy                           0.50      1252\n",
      "   macro avg       0.69      0.52      0.38      1252\n",
      "weighted avg       0.69      0.50      0.37      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06       167\n",
      "           1       0.48      1.00      0.64       147\n",
      "\n",
      "    accuracy                           0.48       314\n",
      "   macro avg       0.74      0.51      0.35       314\n",
      "weighted avg       0.75      0.48      0.33       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.001s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.09       833\n",
      "           1       0.19      1.00      0.32       187\n",
      "\n",
      "    accuracy                           0.22      1020\n",
      "   macro avg       0.60      0.52      0.20      1020\n",
      "weighted avg       0.85      0.22      0.13      1020\n",
      "\n",
      "****************************************************************************************************\n",
      "SVM model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.022s\n",
      "Time to predict train set: 0.015s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69       653\n",
      "           1       0.00      0.00      0.00       599\n",
      "\n",
      "    accuracy                           0.52      1252\n",
      "   macro avg       0.26      0.50      0.34      1252\n",
      "weighted avg       0.27      0.52      0.36      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.019s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69       167\n",
      "           1       0.00      0.00      0.00       147\n",
      "\n",
      "    accuracy                           0.53       314\n",
      "   macro avg       0.27      0.50      0.35       314\n",
      "weighted avg       0.28      0.53      0.37       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.013s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       833\n",
      "           1       0.00      0.00      0.00       187\n",
      "\n",
      "    accuracy                           0.82      1020\n",
      "   macro avg       0.41      0.50      0.45      1020\n",
      "weighted avg       0.67      0.82      0.73      1020\n",
      "\n",
      "****************************************************************************************************\n",
      "DecisionTree model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.003s\n",
      "Time to predict train set: 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       653\n",
      "           1       1.00      1.00      1.00       599\n",
      "\n",
      "    accuracy                           1.00      1252\n",
      "   macro avg       1.00      1.00      1.00      1252\n",
      "weighted avg       1.00      1.00      1.00      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67       167\n",
      "           1       0.62      0.59      0.60       147\n",
      "\n",
      "    accuracy                           0.64       314\n",
      "   macro avg       0.64      0.64      0.64       314\n",
      "weighted avg       0.64      0.64      0.64       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.001s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.65      0.75       833\n",
      "           1       0.30      0.66      0.41       187\n",
      "\n",
      "    accuracy                           0.65      1020\n",
      "   macro avg       0.60      0.66      0.58      1020\n",
      "weighted avg       0.79      0.65      0.69      1020\n",
      "\n",
      "****************************************************************************************************\n",
      "Logistic model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.017s\n",
      "Time to predict train set: 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68       653\n",
      "           1       0.62      0.09      0.15       599\n",
      "\n",
      "    accuracy                           0.54      1252\n",
      "   macro avg       0.58      0.52      0.42      1252\n",
      "weighted avg       0.58      0.54      0.43      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.96      0.71       167\n",
      "           1       0.75      0.14      0.24       147\n",
      "\n",
      "    accuracy                           0.58       314\n",
      "   macro avg       0.65      0.55      0.47       314\n",
      "weighted avg       0.65      0.58      0.49       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.001s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       833\n",
      "           1       0.42      0.15      0.22       187\n",
      "\n",
      "    accuracy                           0.81      1020\n",
      "   macro avg       0.63      0.55      0.55      1020\n",
      "weighted avg       0.76      0.81      0.77      1020\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "cols = ['user_name_labelEncoder', 'num_like_post', 'num_comment_post', 'num_share_post']\n",
    "X, y = train[cols].values, train.label.values\n",
    "X_test, y_test = test[cols].values, test.label.values\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "options = [0,1,2,3,4]\n",
    "names = ['KNN','Gaussian', 'SVM', 'DecisionTree', 'Logistic']\n",
    "\n",
    "for (option, name) in zip(options, names):\n",
    "    print(f'{name} model:')\n",
    "    model = models(X, y, option=option)\n",
    "    _ =  predict(model=model, X=X_test, y=y_test)\n",
    "    print('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.004s\n",
      "Time to predict train set: 0.041s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81       653\n",
      "           1       0.79      0.82      0.80       599\n",
      "\n",
      "    accuracy                           0.81      1252\n",
      "   macro avg       0.81      0.81      0.81      1252\n",
      "weighted avg       0.81      0.81      0.81      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.053s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74       167\n",
      "           1       0.71      0.69      0.70       147\n",
      "\n",
      "    accuracy                           0.72       314\n",
      "   macro avg       0.72      0.72      0.72       314\n",
      "weighted avg       0.72      0.72      0.72       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.029s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80       833\n",
      "           1       0.35      0.68      0.46       187\n",
      "\n",
      "    accuracy                           0.71      1020\n",
      "   macro avg       0.63      0.70      0.63      1020\n",
      "weighted avg       0.81      0.71      0.74      1020\n",
      "\n",
      "****************************************************************************************************\n",
      "Gaussian model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.001s\n",
      "Time to predict train set: 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.06      0.11       653\n",
      "           1       0.49      0.99      0.66       599\n",
      "\n",
      "    accuracy                           0.50      1252\n",
      "   macro avg       0.69      0.52      0.38      1252\n",
      "weighted avg       0.69      0.50      0.37      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06       167\n",
      "           1       0.48      1.00      0.64       147\n",
      "\n",
      "    accuracy                           0.48       314\n",
      "   macro avg       0.74      0.51      0.35       314\n",
      "weighted avg       0.75      0.48      0.33       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.09       833\n",
      "           1       0.19      1.00      0.32       187\n",
      "\n",
      "    accuracy                           0.22      1020\n",
      "   macro avg       0.60      0.52      0.20      1020\n",
      "weighted avg       0.85      0.22      0.13      1020\n",
      "\n",
      "****************************************************************************************************\n",
      "SVM model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.026s\n",
      "Time to predict train set: 0.017s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69       653\n",
      "           1       0.00      0.00      0.00       599\n",
      "\n",
      "    accuracy                           0.52      1252\n",
      "   macro avg       0.26      0.50      0.34      1252\n",
      "weighted avg       0.27      0.52      0.36      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.021s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69       167\n",
      "           1       0.00      0.00      0.00       147\n",
      "\n",
      "    accuracy                           0.53       314\n",
      "   macro avg       0.27      0.50      0.35       314\n",
      "weighted avg       0.28      0.53      0.37       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.016s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       833\n",
      "           1       0.00      0.00      0.00       187\n",
      "\n",
      "    accuracy                           0.82      1020\n",
      "   macro avg       0.41      0.50      0.45      1020\n",
      "weighted avg       0.67      0.82      0.73      1020\n",
      "\n",
      "****************************************************************************************************\n",
      "DecisionTree model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.003s\n",
      "Time to predict train set: 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       653\n",
      "           1       0.96      0.95      0.95       599\n",
      "\n",
      "    accuracy                           0.96      1252\n",
      "   macro avg       0.96      0.96      0.96      1252\n",
      "weighted avg       0.96      0.96      0.96      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.001s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74       167\n",
      "           1       0.71      0.65      0.68       147\n",
      "\n",
      "    accuracy                           0.71       314\n",
      "   macro avg       0.71      0.71      0.71       314\n",
      "weighted avg       0.71      0.71      0.71       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.73      0.81       833\n",
      "           1       0.36      0.67      0.47       187\n",
      "\n",
      "    accuracy                           0.72      1020\n",
      "   macro avg       0.63      0.70      0.64      1020\n",
      "weighted avg       0.81      0.72      0.75      1020\n",
      "\n",
      "****************************************************************************************************\n",
      "Logistic model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.023s\n",
      "Time to predict train set: 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.40      0.54       653\n",
      "           1       0.59      0.94      0.72       599\n",
      "\n",
      "    accuracy                           0.65      1252\n",
      "   macro avg       0.73      0.67      0.63      1252\n",
      "weighted avg       0.74      0.65      0.63      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.43      0.58       167\n",
      "           1       0.59      0.96      0.73       147\n",
      "\n",
      "    accuracy                           0.68       314\n",
      "   macro avg       0.76      0.69      0.66       314\n",
      "weighted avg       0.77      0.68      0.65       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.39      0.56       833\n",
      "           1       0.26      0.95      0.41       187\n",
      "\n",
      "    accuracy                           0.50      1020\n",
      "   macro avg       0.62      0.67      0.48      1020\n",
      "weighted avg       0.84      0.50      0.53      1020\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "cols = ['user_name_freq','num_like_post', 'num_comment_post', 'num_share_post']\n",
    "X, y = train[cols].values, train.label.values\n",
    "X_test, y_test = test[cols].values, test.label.values\n",
    "\n",
    "options = [0,1,2,3,4]\n",
    "names = ['KNN','Gaussian', 'SVM', 'DecisionTree', 'Logistic']\n",
    "\n",
    "for (option, name) in zip(options, names):\n",
    "    print(f'{name} model:')\n",
    "    model = models(X, y, option=option)\n",
    "    _ =  predict(model=model, X=X_test, y=y_test)\n",
    "    print('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.003s\n",
      "Time to predict train set: 0.043s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       653\n",
      "           1       0.74      0.81      0.78       599\n",
      "\n",
      "    accuracy                           0.78      1252\n",
      "   macro avg       0.78      0.78      0.78      1252\n",
      "weighted avg       0.78      0.78      0.78      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.054s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.70       167\n",
      "           1       0.66      0.65      0.66       147\n",
      "\n",
      "    accuracy                           0.68       314\n",
      "   macro avg       0.68      0.68      0.68       314\n",
      "weighted avg       0.68      0.68      0.68       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.034s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.68      0.77       833\n",
      "           1       0.31      0.64      0.42       187\n",
      "\n",
      "    accuracy                           0.67      1020\n",
      "   macro avg       0.60      0.66      0.59      1020\n",
      "weighted avg       0.79      0.67      0.71      1020\n",
      "\n",
      "****************************************************************************************************\n",
      "Gaussian model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.002s\n",
      "Time to predict train set: 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.06      0.11       653\n",
      "           1       0.49      0.99      0.66       599\n",
      "\n",
      "    accuracy                           0.50      1252\n",
      "   macro avg       0.69      0.52      0.38      1252\n",
      "weighted avg       0.69      0.50      0.37      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06       167\n",
      "           1       0.48      1.00      0.64       147\n",
      "\n",
      "    accuracy                           0.48       314\n",
      "   macro avg       0.74      0.51      0.35       314\n",
      "weighted avg       0.75      0.48      0.33       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.001s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.09       833\n",
      "           1       0.19      1.00      0.32       187\n",
      "\n",
      "    accuracy                           0.22      1020\n",
      "   macro avg       0.60      0.52      0.20      1020\n",
      "weighted avg       0.85      0.22      0.13      1020\n",
      "\n",
      "****************************************************************************************************\n",
      "SVM model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.025s\n",
      "Time to predict train set: 0.016s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69       653\n",
      "           1       0.00      0.00      0.00       599\n",
      "\n",
      "    accuracy                           0.52      1252\n",
      "   macro avg       0.26      0.50      0.34      1252\n",
      "weighted avg       0.27      0.52      0.36      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.02s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69       167\n",
      "           1       0.00      0.00      0.00       147\n",
      "\n",
      "    accuracy                           0.53       314\n",
      "   macro avg       0.27      0.50      0.35       314\n",
      "weighted avg       0.28      0.53      0.37       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.013s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       833\n",
      "           1       0.00      0.00      0.00       187\n",
      "\n",
      "    accuracy                           0.82      1020\n",
      "   macro avg       0.41      0.50      0.45      1020\n",
      "weighted avg       0.67      0.82      0.73      1020\n",
      "\n",
      "****************************************************************************************************\n",
      "DecisionTree model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.002s\n",
      "Time to predict train set: 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       653\n",
      "           1       0.95      0.93      0.94       599\n",
      "\n",
      "    accuracy                           0.94      1252\n",
      "   macro avg       0.94      0.94      0.94      1252\n",
      "weighted avg       0.94      0.94      0.94      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72       167\n",
      "           1       0.68      0.67      0.67       147\n",
      "\n",
      "    accuracy                           0.70       314\n",
      "   macro avg       0.70      0.70      0.70       314\n",
      "weighted avg       0.70      0.70      0.70       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.001s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.70      0.79       833\n",
      "           1       0.33      0.65      0.44       187\n",
      "\n",
      "    accuracy                           0.69      1020\n",
      "   macro avg       0.61      0.68      0.61      1020\n",
      "weighted avg       0.80      0.69      0.72      1020\n",
      "\n",
      "****************************************************************************************************\n",
      "Logistic model:\n",
      "Report of train set with 1252 examples: \n",
      "Time to train: 0.008s\n",
      "Time to predict train set: 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.91      0.69       653\n",
      "           1       0.69      0.21      0.32       599\n",
      "\n",
      "    accuracy                           0.58      1252\n",
      "   macro avg       0.62      0.56      0.50      1252\n",
      "weighted avg       0.62      0.58      0.51      1252\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.001s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71       167\n",
      "           1       0.74      0.25      0.38       147\n",
      "\n",
      "    accuracy                           0.61       314\n",
      "   macro avg       0.66      0.59      0.55       314\n",
      "weighted avg       0.66      0.61      0.56       314\n",
      "\n",
      "Time to predict on the test set with 1020 examples: 0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       833\n",
      "           1       0.37      0.24      0.29       187\n",
      "\n",
      "    accuracy                           0.78      1020\n",
      "   macro avg       0.60      0.57      0.58      1020\n",
      "weighted avg       0.75      0.78      0.77      1020\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "cols = ['num_like_post', 'num_comment_post', 'num_share_post']\n",
    "X, y = train[cols].values, train.label.values\n",
    "X_test, y_test = test[cols].values, test.label.values\n",
    "\n",
    "options = [0,1,2,3,4]\n",
    "names = ['KNN','Gaussian', 'SVM', 'DecisionTree', 'Logistic']\n",
    "\n",
    "for (option, name) in zip(options, names):\n",
    "    print(f'{name} model:')\n",
    "    model = models(X, y, option=option)\n",
    "    _ =  predict(model=model, X=X_test, y=y_test)\n",
    "    print('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Logistic model\n",
    "# ##################################################################\n",
    "# # import libraries\n",
    "# # check version number of sampling library\n",
    "# import imblearn\n",
    "# print(imblearn.__version__)\n",
    "\n",
    "# from collections import Counter\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # take data\n",
    "# train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "# test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "\n",
    "# cols = ['user_name_labelEncoder','num_like_post', 'num_comment_post', 'num_share_post']\n",
    "# X_train, y_train = train[cols].values, train.label.values\n",
    "# X_test, y_test = test[cols].values, test.label.values\n",
    "\n",
    "# # define oversampling startegy \n",
    "# oversample = RandomOverSampler(sampling_strategy=0.99)\n",
    "# # fit and apply the transform\n",
    "# X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# # summarize class distribution\n",
    "# print(Counter(y_train_over))\n",
    "# ############################################################\n",
    "# # normalization: adopt the MinMaxScaler and contrain the range of values to be between 0 and 1.\n",
    "# # from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # scaler = MinMaxScaler(feature_range= (0, 1))\n",
    "# # scaler.fit(X_train)\n",
    "# # X_train = scaler.transform(X_train)\n",
    "# # X_test = scaler.transform(X_test)\n",
    "\n",
    "# # # fine tune Logistic Regression model:\n",
    "# # from sklearn.linear_model import LogisticRegression\n",
    "# # logistic_model = LogisticRegression(solver='newton-cg', class_weight=None)\n",
    "# # logistic_model.fit(X_train_over, y_train_over)\n",
    "# # print('Result for logist model:\\n')\n",
    "# # _ =  predict(model=logistic_model, X=X_test, y=y_test)\n",
    "\n",
    "# options = [0,1,2,3,4]\n",
    "# names = ['KNN','Gaussian', 'SVM', 'DecisionTree', 'Logistic']\n",
    "\n",
    "# for (option, name) in zip(options, names):\n",
    "#     print(f'{name} model:')\n",
    "#     model = models(X_train_over, y_train_over, option=option)\n",
    "#     _ =  predict(model=model, X=X_test, y=y_test)\n",
    "#     print('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}