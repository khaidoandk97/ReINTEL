{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from model import * \n",
    "from preprocessing import * \n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = pd.read_csv('cat_data_del_down_pre.csv', encoding='utf8')\n",
    "cat_test = pd.read_csv('cat_test.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1456,) (1456,)\n(845,) (845,)\n"
     ]
    }
   ],
   "source": [
    "X, y = cat_data.post_message_preproced.values, cat_data.label.values\n",
    "X_test, y_test = cat_test.post_message_preproced.values, cat_test.label.values\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN model:\n",
      "Report of train set with 1164 examples: \n",
      "Time to train: 0.026s\n",
      "Time to predict train set: 0.2849s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       637\n",
      "           1       0.84      0.74      0.79       527\n",
      "\n",
      "    accuracy                           0.82      1164\n",
      "   macro avg       0.82      0.81      0.81      1164\n",
      "weighted avg       0.82      0.82      0.82      1164\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.3996s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.75       163\n",
      "           1       0.69      0.65      0.67       129\n",
      "\n",
      "    accuracy                           0.72       292\n",
      "   macro avg       0.71      0.71      0.71       292\n",
      "weighted avg       0.71      0.72      0.71       292\n",
      "\n",
      "Time to predict on the test set with 845 examples: 0.3614s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.85       714\n",
      "           1       0.37      0.75      0.50       131\n",
      "\n",
      "    accuracy                           0.77       845\n",
      "   macro avg       0.66      0.76      0.67       845\n",
      "weighted avg       0.86      0.77      0.79       845\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Gaussian model:\n",
      "Report of train set with 1164 examples: \n",
      "Time to train: 0.354s\n",
      "Time to predict train set: 0.463s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       637\n",
      "           1       1.00      0.98      0.99       527\n",
      "\n",
      "    accuracy                           0.99      1164\n",
      "   macro avg       0.99      0.99      0.99      1164\n",
      "weighted avg       0.99      0.99      0.99      1164\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.544s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       163\n",
      "           1       0.63      0.64      0.63       129\n",
      "\n",
      "    accuracy                           0.67       292\n",
      "   macro avg       0.67      0.67      0.67       292\n",
      "weighted avg       0.67      0.67      0.67       292\n",
      "\n",
      "Time to predict on the test set with 845 examples: 0.2138s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       714\n",
      "           1       0.44      0.93      0.60       131\n",
      "\n",
      "    accuracy                           0.81       845\n",
      "   macro avg       0.71      0.86      0.74       845\n",
      "weighted avg       0.90      0.81      0.83       845\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "SVM model:\n",
      "Report of train set with 1164 examples: \n",
      "Time to train: 6.9517s\n",
      "Time to predict train set: 18.1679s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       637\n",
      "           1       1.00      0.99      1.00       527\n",
      "\n",
      "    accuracy                           1.00      1164\n",
      "   macro avg       1.00      1.00      1.00      1164\n",
      "weighted avg       1.00      1.00      1.00      1164\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 22.7684s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83       163\n",
      "           1       0.86      0.64      0.73       129\n",
      "\n",
      "    accuracy                           0.79       292\n",
      "   macro avg       0.81      0.78      0.78       292\n",
      "weighted avg       0.80      0.79      0.79       292\n",
      "\n",
      "Time to predict on the test set with 845 examples: 14.1192s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       714\n",
      "           1       0.74      0.92      0.82       131\n",
      "\n",
      "    accuracy                           0.94       845\n",
      "   macro avg       0.86      0.93      0.89       845\n",
      "weighted avg       0.95      0.94      0.94       845\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Randomforest model:\n",
      "Report of train set with 1164 examples: \n",
      "Time to train: 5.533s\n",
      "Time to predict train set: 0.1571s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       637\n",
      "           1       1.00      1.00      1.00       527\n",
      "\n",
      "    accuracy                           1.00      1164\n",
      "   macro avg       1.00      1.00      1.00      1164\n",
      "weighted avg       1.00      1.00      1.00      1164\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.2051s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83       163\n",
      "           1       0.86      0.64      0.73       129\n",
      "\n",
      "    accuracy                           0.79       292\n",
      "   macro avg       0.81      0.78      0.78       292\n",
      "weighted avg       0.80      0.79      0.79       292\n",
      "\n",
      "Time to predict on the test set with 845 examples: 0.1251s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       714\n",
      "           1       0.71      0.92      0.80       131\n",
      "\n",
      "    accuracy                           0.93       845\n",
      "   macro avg       0.85      0.93      0.88       845\n",
      "weighted avg       0.94      0.93      0.93       845\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Logistc model:\n",
      "Report of train set with 1164 examples: \n",
      "Time to train: 0.2484s\n",
      "Time to predict train set: 0.022s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       637\n",
      "           1       0.97      0.87      0.92       527\n",
      "\n",
      "    accuracy                           0.93      1164\n",
      "   macro avg       0.94      0.93      0.93      1164\n",
      "weighted avg       0.94      0.93      0.93      1164\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 0.03s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       163\n",
      "           1       0.86      0.70      0.77       129\n",
      "\n",
      "    accuracy                           0.82       292\n",
      "   macro avg       0.82      0.80      0.81       292\n",
      "weighted avg       0.82      0.82      0.81       292\n",
      "\n",
      "Time to predict on the test set with 845 examples: 0.026s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       714\n",
      "           1       0.67      0.82      0.74       131\n",
      "\n",
      "    accuracy                           0.91       845\n",
      "   macro avg       0.82      0.87      0.84       845\n",
      "weighted avg       0.92      0.91      0.91       845\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Stack model:\n",
      "Report of train set with 1164 examples: \n",
      "Time to train: 78.5237s\n",
      "Time to predict train set: 18.4336s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       637\n",
      "           1       1.00      1.00      1.00       527\n",
      "\n",
      "    accuracy                           1.00      1164\n",
      "   macro avg       1.00      1.00      1.00      1164\n",
      "weighted avg       1.00      1.00      1.00      1164\n",
      "\n",
      "\n",
      "Report of validation set:\n",
      "Time to predict validation set 23.6244s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       163\n",
      "           1       0.77      0.73      0.75       129\n",
      "\n",
      "    accuracy                           0.78       292\n",
      "   macro avg       0.78      0.78      0.78       292\n",
      "weighted avg       0.78      0.78      0.78       292\n",
      "\n",
      "Time to predict on the test set with 845 examples: 14.4927s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       714\n",
      "           1       0.62      0.95      0.75       131\n",
      "\n",
      "    accuracy                           0.90       845\n",
      "   macro avg       0.80      0.92      0.84       845\n",
      "weighted avg       0.93      0.90      0.91       845\n",
      "\n",
      "******************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "options = [0,1,2,3,4,5]\n",
    "names = ['KNN','Gaussian', 'SVM', 'Randomforest', 'Logistc', 'Stack']\n",
    "\n",
    "for (option, name) in zip(options, names):\n",
    "    print(f'{name} model:')\n",
    "    model, pipeline = cat_models(X, y, option=option)\n",
    "    _ = cat_predict(model=model, pipeline=pipeline, X=X_test, y=y_test)\n",
    "    print('*'*150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}