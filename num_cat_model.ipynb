{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from preprocessing import *\n",
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        id                                       post_message  label  \\\n",
       "0      448  Hoá đơn tiền điện tăng \"sốc\": Kẽ hở trong việc...      0   \n",
       "1        7  Chủ đầu tư tại Hà Nội tung sản phẩm có mức giá...      0   \n",
       "2     1278  Công an huyện Kbang ra quyết định tạm giữ hình...      0   \n",
       "3     2745  Quá thương tâm\\nPhó Chủ tịch UBND quận Bình Tâ...      0   \n",
       "4     2009  Công ty TNHH Thương mại Thủy sản Vĩnh Long đã ...      0   \n",
       "...    ...                                                ...    ...   \n",
       "1451  4336  TQ 1980 có GDP 190 tỷ USD, thua VN bây giờ. Sa...      1   \n",
       "1452  4343  Virus Corona là vũ khí sinh học? Hiện nay có n...      1   \n",
       "1453  4364  Tin từ Phó Chủ Tịch UBND TPHCM Lê Thanh Liêm.\\...      1   \n",
       "1454  4370  Lời cảnh tỉnh cho các thanh niên dân TỔ...tốc ...      1   \n",
       "1455  4371  Đến bây giờ mới biết chỉ cần học lái xe hạng B...      1   \n",
       "\n",
       "                                 post_message_preproced  \n",
       "0     hoá_đơn tiền điện sốc kẽ hở ghi điện việt_nam ...  \n",
       "1     chủ đầu_tư hà_nội tung sản_phẩm giá tỷ đồng đó...  \n",
       "2     công_an huyện kbang quyết_định tạm hình_sự phạ...  \n",
       "3     thương_tâm phó chủ_tịch ubnd bình_tân tphcm nạ...  \n",
       "4     công_ty tnh thương_mại thuỷ_sản vĩnh_long lợi_...  \n",
       "...                                                 ...  \n",
       "1451  tq gdp tỷ usd thua vn gdp tỷ usd lịch_sử ca gi...  \n",
       "1452  virus corona vũ_khí_sinh_học bằng_chứng virus ...  \n",
       "1453  phó chủ_tịch ubnd tphcm lê_thanh_liêm tp hồ_ch...  \n",
       "1454  cảnh_tỉnh thanh_niên dân tổtốc độ bàn_thờ emoj...  \n",
       "1455  học lái_xe hạng chữa bá bệnh lãnh_đạo_tế xứ th...  \n",
       "\n",
       "[1456 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>post_message</th>\n      <th>label</th>\n      <th>post_message_preproced</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>448</td>\n      <td>Hoá đơn tiền điện tăng \"sốc\": Kẽ hở trong việc...</td>\n      <td>0</td>\n      <td>hoá_đơn tiền điện sốc kẽ hở ghi điện việt_nam ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>Chủ đầu tư tại Hà Nội tung sản phẩm có mức giá...</td>\n      <td>0</td>\n      <td>chủ đầu_tư hà_nội tung sản_phẩm giá tỷ đồng đó...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1278</td>\n      <td>Công an huyện Kbang ra quyết định tạm giữ hình...</td>\n      <td>0</td>\n      <td>công_an huyện kbang quyết_định tạm hình_sự phạ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2745</td>\n      <td>Quá thương tâm\\nPhó Chủ tịch UBND quận Bình Tâ...</td>\n      <td>0</td>\n      <td>thương_tâm phó chủ_tịch ubnd bình_tân tphcm nạ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009</td>\n      <td>Công ty TNHH Thương mại Thủy sản Vĩnh Long đã ...</td>\n      <td>0</td>\n      <td>công_ty tnh thương_mại thuỷ_sản vĩnh_long lợi_...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1451</th>\n      <td>4336</td>\n      <td>TQ 1980 có GDP 190 tỷ USD, thua VN bây giờ. Sa...</td>\n      <td>1</td>\n      <td>tq gdp tỷ usd thua vn gdp tỷ usd lịch_sử ca gi...</td>\n    </tr>\n    <tr>\n      <th>1452</th>\n      <td>4343</td>\n      <td>Virus Corona là vũ khí sinh học? Hiện nay có n...</td>\n      <td>1</td>\n      <td>virus corona vũ_khí_sinh_học bằng_chứng virus ...</td>\n    </tr>\n    <tr>\n      <th>1453</th>\n      <td>4364</td>\n      <td>Tin từ Phó Chủ Tịch UBND TPHCM Lê Thanh Liêm.\\...</td>\n      <td>1</td>\n      <td>phó chủ_tịch ubnd tphcm lê_thanh_liêm tp hồ_ch...</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>4370</td>\n      <td>Lời cảnh tỉnh cho các thanh niên dân TỔ...tốc ...</td>\n      <td>1</td>\n      <td>cảnh_tỉnh thanh_niên dân tổtốc độ bàn_thờ emoj...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>4371</td>\n      <td>Đến bây giờ mới biết chỉ cần học lái xe hạng B...</td>\n      <td>1</td>\n      <td>học lái_xe hạng chữa bá bệnh lãnh_đạo_tế xứ th...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1456 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "cat_data = pd.read_csv('cat_data_del_down_pre.csv', encoding='utf8')\n",
    "\n",
    "cat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        id  num_like_post  num_comment_post  num_share_post  label\n",
       "0     4341            400                15              79      0\n",
       "1     1035          40000              1400            2600      0\n",
       "2     2896             13                 1               0      0\n",
       "3     3941              6                 0               0      0\n",
       "4     1805              6                 1               0      0\n",
       "...    ...            ...               ...             ...    ...\n",
       "1451  4336             25                 5               0      1\n",
       "1452  4343           4800               436            3100      1\n",
       "1453  4364             13                 5               0      1\n",
       "1454  4370              3                 1               0      1\n",
       "1455  4371            144                38              87      1\n",
       "\n",
       "[1456 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>num_like_post</th>\n      <th>num_comment_post</th>\n      <th>num_share_post</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4341</td>\n      <td>400</td>\n      <td>15</td>\n      <td>79</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1035</td>\n      <td>40000</td>\n      <td>1400</td>\n      <td>2600</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2896</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3941</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1805</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1451</th>\n      <td>4336</td>\n      <td>25</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1452</th>\n      <td>4343</td>\n      <td>4800</td>\n      <td>436</td>\n      <td>3100</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1453</th>\n      <td>4364</td>\n      <td>13</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>4370</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>4371</td>\n      <td>144</td>\n      <td>38</td>\n      <td>87</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1456 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "num_data = pd.read_csv('num_data_del_down.csv', encoding='utf8')\n",
    "\n",
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1456, 11581)\n"
     ]
    }
   ],
   "source": [
    "X_cat = cat_data.post_message_preproced.values\n",
    "\n",
    "pipeline, X_tfidf = text_tfidf(X_cat)\n",
    "\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1456, 3)\n"
     ]
    }
   ],
   "source": [
    "cols = ['num_like_post', 'num_comment_post', 'num_share_post']\n",
    "X_num, y = num_data[cols].values, num_data.label.values.reshape(-1,1)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1456, 11584)\n"
     ]
    }
   ],
   "source": [
    "data = np.hstack((X_tfidf, X_num))\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN model:\n",
      "Report of train set: \n",
      "Time to predict train set: 0.6629s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       637\n",
      "           1       0.76      0.71      0.73       527\n",
      "\n",
      "    accuracy                           0.76      1164\n",
      "   macro avg       0.76      0.76      0.76      1164\n",
      "weighted avg       0.76      0.76      0.76      1164\n",
      "\n",
      "\n",
      "Report of test set:\n",
      "Time to predict test set 0.9668s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       163\n",
      "           1       0.68      0.65      0.66       129\n",
      "\n",
      "    accuracy                           0.71       292\n",
      "   macro avg       0.70      0.70      0.70       292\n",
      "weighted avg       0.71      0.71      0.71       292\n",
      "\n",
      "**************************************************************************************************************************************************************************\n",
      "Gaussian model:\n",
      "Report of train set: \n",
      "Time to predict train set: 0.4762s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.95      0.74       637\n",
      "           1       0.82      0.25      0.39       527\n",
      "\n",
      "    accuracy                           0.64      1164\n",
      "   macro avg       0.71      0.60      0.56      1164\n",
      "weighted avg       0.70      0.64      0.58      1164\n",
      "\n",
      "\n",
      "Report of test set:\n",
      "Time to predict test set 0.5956s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.96      0.74       163\n",
      "           1       0.79      0.17      0.28       129\n",
      "\n",
      "    accuracy                           0.61       292\n",
      "   macro avg       0.69      0.57      0.51       292\n",
      "weighted avg       0.68      0.61      0.53       292\n",
      "\n",
      "**************************************************************************************************************************************************************************\n",
      "SVM model:\n",
      "Report of train set: \n",
      "Time to predict train set: 23.4805s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.72       637\n",
      "           1       0.72      0.14      0.24       527\n",
      "\n",
      "    accuracy                           0.59      1164\n",
      "   macro avg       0.65      0.55      0.48      1164\n",
      "weighted avg       0.64      0.59      0.50      1164\n",
      "\n",
      "\n",
      "Report of test set:\n",
      "Time to predict test set 29.8157s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.96      0.72       163\n",
      "           1       0.67      0.09      0.16       129\n",
      "\n",
      "    accuracy                           0.58       292\n",
      "   macro avg       0.62      0.53      0.44       292\n",
      "weighted avg       0.61      0.58      0.47       292\n",
      "\n",
      "**************************************************************************************************************************************************************************\n",
      "Randomforest model:\n",
      "Report of train set: \n",
      "Time to predict train set: 0.1647s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       637\n",
      "           1       1.00      1.00      1.00       527\n",
      "\n",
      "    accuracy                           1.00      1164\n",
      "   macro avg       1.00      1.00      1.00      1164\n",
      "weighted avg       1.00      1.00      1.00      1164\n",
      "\n",
      "\n",
      "Report of test set:\n",
      "Time to predict test set 0.2349s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85       163\n",
      "           1       0.90      0.66      0.76       129\n",
      "\n",
      "    accuracy                           0.82       292\n",
      "   macro avg       0.84      0.80      0.81       292\n",
      "weighted avg       0.83      0.82      0.81       292\n",
      "\n",
      "**************************************************************************************************************************************************************************\n",
      "Logistc model:\n",
      "Report of train set: \n",
      "Time to predict train set: 0.0325s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       637\n",
      "           1       0.92      0.76      0.83       527\n",
      "\n",
      "    accuracy                           0.86      1164\n",
      "   macro avg       0.87      0.85      0.86      1164\n",
      "weighted avg       0.87      0.86      0.86      1164\n",
      "\n",
      "\n",
      "Report of test set:\n",
      "Time to predict test set 0.04s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81       163\n",
      "           1       0.82      0.59      0.68       129\n",
      "\n",
      "    accuracy                           0.76       292\n",
      "   macro avg       0.78      0.74      0.75       292\n",
      "weighted avg       0.77      0.76      0.75       292\n",
      "\n",
      "**************************************************************************************************************************************************************************\n",
      "Stack model:\n",
      "Report of train set: \n",
      "Time to predict train set: 23.5499s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       637\n",
      "           1       1.00      1.00      1.00       527\n",
      "\n",
      "    accuracy                           1.00      1164\n",
      "   macro avg       1.00      1.00      1.00      1164\n",
      "weighted avg       1.00      1.00      1.00      1164\n",
      "\n",
      "\n",
      "Report of test set:\n",
      "Time to predict test set 29.4536s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       163\n",
      "           1       0.80      0.76      0.78       129\n",
      "\n",
      "    accuracy                           0.81       292\n",
      "   macro avg       0.81      0.81      0.81       292\n",
      "weighted avg       0.81      0.81      0.81       292\n",
      "\n",
      "**************************************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "options = [0,1,2,3,4,5]\n",
    "names = ['KNN','Gaussian', 'SVM', 'Randomforest', 'Logistc', 'Stack']\n",
    "\n",
    "for (option, name) in zip(options, names):\n",
    "    print(f'{name} model:')\n",
    "    _ = models(data, y, option=option)\n",
    "    print('*'*170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 1456, 100)         1158500   \n_________________________________________________________________\ndense_7 (Dense)              (None, 1456, 200)         20200     \n_________________________________________________________________\ndense_8 (Dense)              (None, 1456, 1)           201       \n=================================================================\nTotal params: 1,178,901\nTrainable params: 1,178,901\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape=data.shape))\n",
    "model.add(layers.Dense(units=100, activation='relu'))\n",
    "model.add(layers.Dense(units=200, activation='relu'))\n",
    "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1456, 11584) for input Tensor(\"input_4:0\", shape=(None, 1456, 11584), dtype=float32), but it was called on an input with incompatible shape (None, 11584).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1456, 11584) for input Tensor(\"input_4:0\", shape=(None, 1456, 11584), dtype=float32), but it was called on an input with incompatible shape (None, 11584).\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 0.2479 - mae: 0.4137 - acc: 0.7021WARNING:tensorflow:Model was constructed with shape (None, 1456, 11584) for input Tensor(\"input_4:0\", shape=(None, 1456, 11584), dtype=float32), but it was called on an input with incompatible shape (None, 11584).\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.2504 - mae: 0.4136 - acc: 0.6976 - val_loss: 0.4336 - val_mae: 0.5688 - val_acc: 0.2705\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2111 - mae: 0.3431 - acc: 0.7242 - val_loss: 0.6784 - val_mae: 0.8060 - val_acc: 0.0171\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.2075 - mae: 0.3229 - acc: 0.7337 - val_loss: 0.5468 - val_mae: 0.6621 - val_acc: 0.2877\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2403 - mae: 0.3027 - acc: 0.7156 - val_loss: 0.7703 - val_mae: 0.8586 - val_acc: 0.0479\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2051 - mae: 0.2781 - acc: 0.7775 - val_loss: 0.8423 - val_mae: 0.8783 - val_acc: 0.0822\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2293 - mae: 0.2664 - acc: 0.7646 - val_loss: 0.6595 - val_mae: 0.7302 - val_acc: 0.2877\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1744 - mae: 0.2132 - acc: 0.8179 - val_loss: 0.8023 - val_mae: 0.8733 - val_acc: 0.0788\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.2132 - mae: 0.2452 - acc: 0.7784 - val_loss: 0.5098 - val_mae: 0.6020 - val_acc: 0.4521\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1324 - mae: 0.1736 - acc: 0.8531 - val_loss: 0.2884 - val_mae: 0.3677 - val_acc: 0.6507\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.1468 - mae: 0.1755 - acc: 0.8411 - val_loss: 0.2365 - val_mae: 0.3168 - val_acc: 0.7055\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1285 - mae: 0.1531 - acc: 0.8643 - val_loss: 0.3564 - val_mae: 0.4445 - val_acc: 0.5719\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1330 - mae: 0.1577 - acc: 0.8582 - val_loss: 0.5841 - val_mae: 0.6419 - val_acc: 0.3425\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2067 - mae: 0.2233 - acc: 0.7878 - val_loss: 0.7828 - val_mae: 0.8391 - val_acc: 0.1507\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1784 - mae: 0.1996 - acc: 0.8162 - val_loss: 0.4589 - val_mae: 0.5191 - val_acc: 0.5103\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.1660 - mae: 0.1835 - acc: 0.8299 - val_loss: 0.5194 - val_mae: 0.5830 - val_acc: 0.4178\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1394 - mae: 0.1623 - acc: 0.8548 - val_loss: 0.4697 - val_mae: 0.5513 - val_acc: 0.4555\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1378 - mae: 0.1570 - acc: 0.8522 - val_loss: 0.3828 - val_mae: 0.4459 - val_acc: 0.5616\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1418 - mae: 0.1571 - acc: 0.8540 - val_loss: 0.1354 - val_mae: 0.1866 - val_acc: 0.8253\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1358 - mae: 0.1487 - acc: 0.8582 - val_loss: 0.2067 - val_mae: 0.2552 - val_acc: 0.7603\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1316 - mae: 0.1450 - acc: 0.8625 - val_loss: 0.6656 - val_mae: 0.6979 - val_acc: 0.2945\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1633 - mae: 0.1741 - acc: 0.8290 - val_loss: 0.4463 - val_mae: 0.4900 - val_acc: 0.5068\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1486 - mae: 0.1587 - acc: 0.8479 - val_loss: 0.5916 - val_mae: 0.6355 - val_acc: 0.3630\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1385 - mae: 0.1474 - acc: 0.8574 - val_loss: 0.4747 - val_mae: 0.5201 - val_acc: 0.4795\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1280 - mae: 0.1372 - acc: 0.8660 - val_loss: 0.3802 - val_mae: 0.4327 - val_acc: 0.5719\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1223 - mae: 0.1319 - acc: 0.8754 - val_loss: 0.2718 - val_mae: 0.3232 - val_acc: 0.6952\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1042 - mae: 0.1193 - acc: 0.8918 - val_loss: 0.4698 - val_mae: 0.5380 - val_acc: 0.4658\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1057 - mae: 0.1210 - acc: 0.8832 - val_loss: 0.2334 - val_mae: 0.3134 - val_acc: 0.7055\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1189 - mae: 0.1326 - acc: 0.8754 - val_loss: 0.5342 - val_mae: 0.5966 - val_acc: 0.4007\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.1015 - mae: 0.1110 - acc: 0.8952 - val_loss: 0.1529 - val_mae: 0.1964 - val_acc: 0.8048\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1106 - mae: 0.1250 - acc: 0.8849 - val_loss: 0.2040 - val_mae: 0.2547 - val_acc: 0.7568\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0980 - mae: 0.1084 - acc: 0.8960 - val_loss: 0.4987 - val_mae: 0.5689 - val_acc: 0.4349\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.3224 - mae: 0.3379 - acc: 0.6684 - val_loss: 0.3709 - val_mae: 0.4114 - val_acc: 0.5856\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1509 - mae: 0.1631 - acc: 0.8419 - val_loss: 0.4199 - val_mae: 0.4562 - val_acc: 0.5514\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1380 - mae: 0.1451 - acc: 0.8574 - val_loss: 0.2650 - val_mae: 0.3075 - val_acc: 0.7055\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1165 - mae: 0.1246 - acc: 0.8789 - val_loss: 0.6139 - val_mae: 0.6533 - val_acc: 0.3356\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1504 - mae: 0.1597 - acc: 0.8436 - val_loss: 0.0268 - val_mae: 0.0392 - val_acc: 0.9658\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.3948 - mae: 0.4046 - acc: 0.5979 - val_loss: 0.0799 - val_mae: 0.0952 - val_acc: 0.9041\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.3117 - mae: 0.3177 - acc: 0.6838 - val_loss: 0.2936 - val_mae: 0.3228 - val_acc: 0.6849\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1584 - mae: 0.1671 - acc: 0.8359 - val_loss: 0.2481 - val_mae: 0.2767 - val_acc: 0.7192\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2119 - mae: 0.2177 - acc: 0.7835 - val_loss: 0.8558 - val_mae: 0.8622 - val_acc: 0.1336\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2208 - mae: 0.2255 - acc: 0.7758 - val_loss: 0.6189 - val_mae: 0.6404 - val_acc: 0.3459\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1469 - mae: 0.1522 - acc: 0.8505 - val_loss: 0.3089 - val_mae: 0.3434 - val_acc: 0.6404\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1374 - mae: 0.1435 - acc: 0.8582 - val_loss: 0.7161 - val_mae: 0.7377 - val_acc: 0.2534\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1374 - mae: 0.1421 - acc: 0.8600 - val_loss: 0.0212 - val_mae: 0.0347 - val_acc: 0.9760\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2454 - mae: 0.2528 - acc: 0.7500 - val_loss: 0.0813 - val_mae: 0.0994 - val_acc: 0.8938\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1541 - mae: 0.1571 - acc: 0.8445 - val_loss: 0.6041 - val_mae: 0.6256 - val_acc: 0.3733\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1329 - mae: 0.1369 - acc: 0.8651 - val_loss: 0.5063 - val_mae: 0.5309 - val_acc: 0.4726\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1367 - mae: 0.1387 - acc: 0.8608 - val_loss: 0.3082 - val_mae: 0.3319 - val_acc: 0.6781\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1361 - mae: 0.1383 - acc: 0.8625 - val_loss: 0.4887 - val_mae: 0.5147 - val_acc: 0.4829\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1252 - mae: 0.1272 - acc: 0.8737 - val_loss: 0.3394 - val_mae: 0.3654 - val_acc: 0.6370\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2548 - mae: 0.2586 - acc: 0.7431 - val_loss: 0.0397 - val_mae: 0.0536 - val_acc: 0.9521\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.3365 - mae: 0.3413 - acc: 0.6624 - val_loss: 0.1715 - val_mae: 0.1900 - val_acc: 0.8151\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1291 - mae: 0.1336 - acc: 0.8686 - val_loss: 0.4961 - val_mae: 0.5229 - val_acc: 0.4760\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2055 - mae: 0.2087 - acc: 0.7930 - val_loss: 0.9784 - val_mae: 0.9823 - val_acc: 0.0171\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2694 - mae: 0.2720 - acc: 0.7294 - val_loss: 0.9682 - val_mae: 0.9731 - val_acc: 0.0274\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2619 - mae: 0.2632 - acc: 0.7380 - val_loss: 0.9545 - val_mae: 0.9614 - val_acc: 0.0342\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2573 - mae: 0.2581 - acc: 0.7423 - val_loss: 0.9452 - val_mae: 0.9507 - val_acc: 0.0548\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2545 - mae: 0.2551 - acc: 0.7457 - val_loss: 0.9430 - val_mae: 0.9472 - val_acc: 0.0548\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2541 - mae: 0.2543 - acc: 0.7457 - val_loss: 0.9420 - val_mae: 0.9457 - val_acc: 0.0548\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2531 - mae: 0.2534 - acc: 0.7466 - val_loss: 0.9404 - val_mae: 0.9440 - val_acc: 0.0548\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2510 - mae: 0.2516 - acc: 0.7483 - val_loss: 0.9369 - val_mae: 0.9412 - val_acc: 0.0548\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2497 - mae: 0.2500 - acc: 0.7500 - val_loss: 0.9335 - val_mae: 0.9387 - val_acc: 0.0582\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2442 - mae: 0.2451 - acc: 0.7552 - val_loss: 0.9125 - val_mae: 0.9221 - val_acc: 0.0753\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2220 - mae: 0.2242 - acc: 0.7758 - val_loss: 0.7094 - val_mae: 0.7232 - val_acc: 0.2808\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1717 - mae: 0.1780 - acc: 0.8256 - val_loss: 0.5050 - val_mae: 0.5174 - val_acc: 0.4829\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1596 - mae: 0.1618 - acc: 0.8385 - val_loss: 0.6863 - val_mae: 0.7040 - val_acc: 0.2979\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1648 - mae: 0.1671 - acc: 0.8333 - val_loss: 0.5750 - val_mae: 0.5887 - val_acc: 0.4178\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1460 - mae: 0.1497 - acc: 0.8514 - val_loss: 0.3433 - val_mae: 0.3584 - val_acc: 0.6473\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1369 - mae: 0.1399 - acc: 0.8634 - val_loss: 0.4260 - val_mae: 0.4383 - val_acc: 0.5616\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1591 - mae: 0.1648 - acc: 0.8376 - val_loss: 0.1532 - val_mae: 0.1679 - val_acc: 0.8390\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1358 - mae: 0.1379 - acc: 0.8634 - val_loss: 0.4067 - val_mae: 0.4243 - val_acc: 0.5788\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1338 - mae: 0.1355 - acc: 0.8643 - val_loss: 0.6587 - val_mae: 0.6742 - val_acc: 0.3253\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1321 - mae: 0.1338 - acc: 0.8660 - val_loss: 0.5299 - val_mae: 0.5510 - val_acc: 0.4452\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1212 - mae: 0.1223 - acc: 0.8771 - val_loss: 0.3852 - val_mae: 0.4051 - val_acc: 0.5925\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1178 - mae: 0.1187 - acc: 0.8814 - val_loss: 0.3381 - val_mae: 0.3616 - val_acc: 0.6404\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2421 - mae: 0.2491 - acc: 0.7534 - val_loss: 0.0260 - val_mae: 0.0332 - val_acc: 0.9692\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2640 - mae: 0.2682 - acc: 0.7328 - val_loss: 0.9497 - val_mae: 0.9534 - val_acc: 0.0479\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.2457 - mae: 0.2476 - acc: 0.7534 - val_loss: 0.9473 - val_mae: 0.9496 - val_acc: 0.0514\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2392 - mae: 0.2398 - acc: 0.7603 - val_loss: 0.9386 - val_mae: 0.9416 - val_acc: 0.0582\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2307 - mae: 0.2315 - acc: 0.7680 - val_loss: 0.9061 - val_mae: 0.9153 - val_acc: 0.0753\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1998 - mae: 0.2015 - acc: 0.7990 - val_loss: 0.6818 - val_mae: 0.6936 - val_acc: 0.3048\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1811 - mae: 0.1859 - acc: 0.8162 - val_loss: 0.0136 - val_mae: 0.0146 - val_acc: 0.9863\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.3111 - mae: 0.3166 - acc: 0.6873 - val_loss: 0.1127 - val_mae: 0.1243 - val_acc: 0.8767\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1656 - mae: 0.1673 - acc: 0.8316 - val_loss: 0.3919 - val_mae: 0.4015 - val_acc: 0.5993\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1530 - mae: 0.1539 - acc: 0.8471 - val_loss: 0.3357 - val_mae: 0.3492 - val_acc: 0.6575\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1596 - mae: 0.1606 - acc: 0.8393 - val_loss: 0.5744 - val_mae: 0.5849 - val_acc: 0.4178\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1620 - mae: 0.1638 - acc: 0.8368 - val_loss: 0.4553 - val_mae: 0.4636 - val_acc: 0.5377\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1492 - mae: 0.1504 - acc: 0.8497 - val_loss: 0.3771 - val_mae: 0.3858 - val_acc: 0.6130\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1438 - mae: 0.1449 - acc: 0.8557 - val_loss: 0.4242 - val_mae: 0.4322 - val_acc: 0.5651\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.1413 - mae: 0.1421 - acc: 0.8574 - val_loss: 0.4398 - val_mae: 0.4484 - val_acc: 0.5479\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.1406 - mae: 0.1418 - acc: 0.8591 - val_loss: 0.4704 - val_mae: 0.4786 - val_acc: 0.5274\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1421 - mae: 0.1430 - acc: 0.8574 - val_loss: 0.4345 - val_mae: 0.4433 - val_acc: 0.5616\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1393 - mae: 0.1397 - acc: 0.8600 - val_loss: 0.3875 - val_mae: 0.3971 - val_acc: 0.5993\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1383 - mae: 0.1384 - acc: 0.8617 - val_loss: 0.3989 - val_mae: 0.4080 - val_acc: 0.5890\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.1366 - mae: 0.1368 - acc: 0.8634 - val_loss: 0.3761 - val_mae: 0.3869 - val_acc: 0.6130\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.1365 - mae: 0.1366 - acc: 0.8634 - val_loss: 0.3691 - val_mae: 0.3795 - val_acc: 0.6233\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.1408 - mae: 0.1424 - acc: 0.8582 - val_loss: 0.4962 - val_mae: 0.5043 - val_acc: 0.4966\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1408 - mae: 0.1418 - acc: 0.8574 - val_loss: 0.5569 - val_mae: 0.5666 - val_acc: 0.4384\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.1387 - mae: 0.1399 - acc: 0.8600 - val_loss: 0.5666 - val_mae: 0.5759 - val_acc: 0.4247\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1582 - mae: 0.1600 - acc: 0.8385 - val_loss: 0.5047 - val_mae: 0.5143 - val_acc: 0.4897\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a58f898370>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
    "model.fit(data, y, epochs=100, batch_size=32, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}